{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c2b4547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\bhargavi\\anaconda3\\lib\\site-packages (1.4.4)\n",
      "Requirement already satisfied: pillow in c:\\users\\bhargavi\\anaconda3\\lib\\site-packages (9.2.0)\n",
      "Requirement already satisfied: pytesseract in c:\\users\\bhargavi\\anaconda3\\lib\\site-packages (0.3.10)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\bhargavi\\anaconda3\\lib\\site-packages (1.0.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\bhargavi\\anaconda3\\lib\\site-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\bhargavi\\anaconda3\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\bhargavi\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\bhargavi\\anaconda3\\lib\\site-packages (from pytesseract) (23.2)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\bhargavi\\anaconda3\\lib\\site-packages (from scikit-learn) (1.9.1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\bhargavi\\anaconda3\\lib\\site-packages (from scikit-learn) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\bhargavi\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\bhargavi\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Collecting numpy>=1.18.5\n",
      "  Using cached numpy-1.24.4-cp39-cp39-win_amd64.whl (14.9 MB)\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.4\n",
      "    Uninstalling numpy-1.26.4:\n",
      "      Successfully uninstalled numpy-1.26.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'C:\\\\Users\\\\Bhargavi\\\\anaconda3\\\\Lib\\\\site-packages\\\\~umpy.libs\\\\libopenblas64__v0.3.23-293-gc2f4bdbb-gcc_10_3_0-2bde3a66a51006b2b53eb373ff767a3f.dll'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas pillow pytesseract scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "717093d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['student_resource 3', '__MACOSX']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "zip_file_path = 'Folder.zip'\n",
    "extracted_folder_path = 'extracted_hackathon_files/'\n",
    "\n",
    "# Unzip the file\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extracted_folder_path)\n",
    "\n",
    "# Check the files\n",
    "os.listdir(extracted_folder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e444664",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_link</th>\n",
       "      <th>group_id</th>\n",
       "      <th>entity_name</th>\n",
       "      <th>entity_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://m.media-amazon.com/images/I/61I9XdN6OF...</td>\n",
       "      <td>748919</td>\n",
       "      <td>item_weight</td>\n",
       "      <td>500.0 gram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://m.media-amazon.com/images/I/71gSRbyXmo...</td>\n",
       "      <td>916768</td>\n",
       "      <td>item_volume</td>\n",
       "      <td>1.0 cup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://m.media-amazon.com/images/I/61BZ4zrjZX...</td>\n",
       "      <td>459516</td>\n",
       "      <td>item_weight</td>\n",
       "      <td>0.709 gram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://m.media-amazon.com/images/I/612mrlqiI4...</td>\n",
       "      <td>459516</td>\n",
       "      <td>item_weight</td>\n",
       "      <td>0.709 gram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://m.media-amazon.com/images/I/617Tl40LOX...</td>\n",
       "      <td>731432</td>\n",
       "      <td>item_weight</td>\n",
       "      <td>1400 milligram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>https://m.media-amazon.com/images/I/61QsBSE7jg...</td>\n",
       "      <td>731432</td>\n",
       "      <td>item_weight</td>\n",
       "      <td>1400 milligram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>https://m.media-amazon.com/images/I/81xsq6vf2q...</td>\n",
       "      <td>731432</td>\n",
       "      <td>item_weight</td>\n",
       "      <td>1400 milligram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>https://m.media-amazon.com/images/I/71DiLRHeZd...</td>\n",
       "      <td>731432</td>\n",
       "      <td>item_weight</td>\n",
       "      <td>1400 milligram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>https://m.media-amazon.com/images/I/91Cma3Rzse...</td>\n",
       "      <td>731432</td>\n",
       "      <td>item_weight</td>\n",
       "      <td>1400 milligram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>https://m.media-amazon.com/images/I/71jBLhmTNl...</td>\n",
       "      <td>731432</td>\n",
       "      <td>item_weight</td>\n",
       "      <td>1400 milligram</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          image_link  group_id  entity_name  \\\n",
       "0  https://m.media-amazon.com/images/I/61I9XdN6OF...    748919  item_weight   \n",
       "1  https://m.media-amazon.com/images/I/71gSRbyXmo...    916768  item_volume   \n",
       "2  https://m.media-amazon.com/images/I/61BZ4zrjZX...    459516  item_weight   \n",
       "3  https://m.media-amazon.com/images/I/612mrlqiI4...    459516  item_weight   \n",
       "4  https://m.media-amazon.com/images/I/617Tl40LOX...    731432  item_weight   \n",
       "5  https://m.media-amazon.com/images/I/61QsBSE7jg...    731432  item_weight   \n",
       "6  https://m.media-amazon.com/images/I/81xsq6vf2q...    731432  item_weight   \n",
       "7  https://m.media-amazon.com/images/I/71DiLRHeZd...    731432  item_weight   \n",
       "8  https://m.media-amazon.com/images/I/91Cma3Rzse...    731432  item_weight   \n",
       "9  https://m.media-amazon.com/images/I/71jBLhmTNl...    731432  item_weight   \n",
       "\n",
       "     entity_value  \n",
       "0      500.0 gram  \n",
       "1         1.0 cup  \n",
       "2      0.709 gram  \n",
       "3      0.709 gram  \n",
       "4  1400 milligram  \n",
       "5  1400 milligram  \n",
       "6  1400 milligram  \n",
       "7  1400 milligram  \n",
       "8  1400 milligram  \n",
       "9  1400 milligram  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the train and test datasets\n",
    "train_df = pd.read_csv('student_resource 3/dataset/train.csv')\n",
    "test_df = pd.read_csv('student_resource 3/dataset/test.csv')\n",
    "\n",
    "# Display the first few rows to understand the data\n",
    "train_df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9faa8cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['image_link', 'group_id', 'entity_name', 'entity_value'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Inspect the columns of the DataFrame\n",
    "print(train_df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52207fa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          image_link  group_id  entity_name  \\\n",
      "0  https://m.media-amazon.com/images/I/61I9XdN6OF...    748919  item_weight   \n",
      "1  https://m.media-amazon.com/images/I/71gSRbyXmo...    916768  item_volume   \n",
      "2  https://m.media-amazon.com/images/I/61BZ4zrjZX...    459516  item_weight   \n",
      "3  https://m.media-amazon.com/images/I/612mrlqiI4...    459516  item_weight   \n",
      "4  https://m.media-amazon.com/images/I/617Tl40LOX...    731432  item_weight   \n",
      "\n",
      "     entity_value  \n",
      "0      500.0 gram  \n",
      "1         1.0 cup  \n",
      "2      0.709 gram  \n",
      "3      0.709 gram  \n",
      "4  1400 milligram  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "train_df = pd.read_csv('student_resource 3/dataset/train.csv')\n",
    "\n",
    "# Inspect the DataFrame to check the column names and content\n",
    "print(train_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa3a0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file into a Pandas DataFrame\n",
    "train_df = pd.read_csv('student_resource 3/dataset/train.csv')\n",
    "\n",
    "# Function to download and save images\n",
    "def download_image(url, file_path):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        with open(file_path, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "\n",
    "# Create the images directory if it doesn't exist\n",
    "if not os.path.exists('images'):\n",
    "    os.makedirs('images')\n",
    "\n",
    "# Example: Download images from train.csv\n",
    "for idx, row in train_df.iterrows():\n",
    "    image_url = row['image_link']\n",
    "    image_path = f'images/{row[\"group_id\"]}.jpg'  # Assuming there's an 'index' column in the CSV\n",
    "    download_image(image_url, image_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2bb425",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "\n",
    "# Preprocessing function for images\n",
    "def preprocess_image(image_path):\n",
    "    img = Image.open(image_path)\n",
    "    img = img.convert('L')  # convert to grayscale\n",
    "    img = img.resize((256, 256))  # resize for consistency\n",
    "    return img\n",
    "\n",
    "# Function to extract text using Tesseract\n",
    "def extract_text_from_image(image_path):\n",
    "    img = preprocess_image(image_path)\n",
    "    text = pytesseract.image_to_string(img)\n",
    "    return text\n",
    "\n",
    "# Example: Extract text from the downloaded images\n",
    "train_df['extracted_text'] = train_df['index'].apply(lambda x: extract_text_from_image(f'images/{x}.jpg'))\n",
    "train_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806d3c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Function to extract numerical values from text\n",
    "def extract_numerical_value(text):\n",
    "    # Use regex to find numbers in the text\n",
    "    match = re.search(r'(\\d+(\\.\\d+)?)', text)\n",
    "    return float(match.group()) if match else None\n",
    "\n",
    "# Apply the function to the extracted text\n",
    "train_df['numerical_value'] = train_df['extracted_text'].apply(extract_numerical_value)\n",
    "train_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710dfcca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Split data into features and labels\n",
    "X = train_df[['numerical_value']]  # You can add more features if needed\n",
    "y = train_df['entity_value']\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a Random Forest Regressor\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Validate the model\n",
    "val_predictions = model.predict(X_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a17399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download test images and extract text\n",
    "for idx, row in test_df.iterrows():\n",
    "    image_url = row['image_link']\n",
    "    image_path = f'images/{row[\"group_id\"]}.jpg'\n",
    "    download_image(image_url, image_path)\n",
    "    test_df.at[idx, 'extracted_text'] = extract_text_from_image(image_path)\n",
    "\n",
    "# Extract numerical values from test images\n",
    "test_df['numerical_value'] = test_df['extracted_text'].apply(extract_numerical_value)\n",
    "\n",
    "# Make predictions on the test set\n",
    "test_df['prediction'] = model.predict(test_df[['numerical_value']])\n",
    "\n",
    "# Save predictions in the required format\n",
    "output_df = test_df[['index', 'prediction']]\n",
    "output_df.to_csv('test_out.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff0fe5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example to run sanity checker\n",
    "!python path_to_sanity.py --input_file test_out.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c574e41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb48badc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import easyocr\n",
    "\n",
    "# Initialize the EasyOCR reader\n",
    "reader = easyocr.Reader(['en'])  # You can add more languages if needed, e.g., ['en', 'fr']\n",
    "\n",
    "# Function to extract text using EasyOCR\n",
    "def extract_text_easyocr(image_path):\n",
    "    result = reader.readtext(image_path, detail=0)  # detail=0 returns just the text\n",
    "    return \" \".join(result)\n",
    "\n",
    "# Example: Extract text from the downloaded images\n",
    "train_df['extracted_text'] = train_df['index'].apply(lambda x: extract_text_easyocr(f'images/{x}.jpg'))\n",
    "train_df.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
